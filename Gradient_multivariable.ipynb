"""Theta is the vector representing coefficients (intercept, area, bedrooms)"""
theta = np.matrix(np.array([0,0,0])) 
alpha = 0.01
iterations = 1000
""" define cost functiontakes in theta (current values of coefficients b0, b1, b2), X and yreturns total cost at current b0, b1, b2"""

def compute_cost(X, y, theta):
    return np.sum(np.square(np.matmul(X, theta) - y)) / (2 * len(y))

"""gradient descenttakes in current X, y, learning rate alpha, num_itersreturns cost (notice it uses the cost function defined above)"""

def gradient_descent_multi(X, y, theta, alpha, iterations):
    theta = np.zeros(X.shape[1])
    m = len(X)
    gdm_df = pd.DataFrame( columns = ['Bets','cost'])

    for i in range(iterations):
        gradient = (1/m) * np.matmul(X.T, np.matmul(X, theta) - y)
        theta = theta - alpha * gradient
        cost = compute_cost(X, y, theta)
        gdm_df.loc[i] = [theta,cost]

    return gdm_df

"""print costs with various values of coefficients b0, b1, b2"""
gradient_descent_multi(X, y, theta, alpha, iterations)
